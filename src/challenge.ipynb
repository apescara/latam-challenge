{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En este archivo puedes escribir lo que estimes conveniente. Te recomendamos detallar tu solución y todas las suposiciones que estás considerando. Aquí puedes ejecutar las funciones que definiste en los otros archivos de la carpeta src, medir el tiempo, memoria, etc."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = \"farmers-protest-tweets-2021-2-4.json\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The line_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext line_profiler\n",
      "The memory_profiler extension is already loaded. To reload it, use:\n",
      "  %reload_ext memory_profiler\n"
     ]
    }
   ],
   "source": [
    "%load_ext line_profiler\n",
    "%load_ext memory_profiler"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se tomaron dos enfoques distintos. El primero consistió en leer los datos con la librería JSON y luego trabajar la información con Pandas. Para el segundo enfoque se utilizó PySpark para la lectura y tratamiento de los datos.\n",
    "\n",
    "En cuanto al tiempo de ejecución con el primer método, se observó que los tiempos eran estables y repetibles, con una duración de alrededor de 11 segundos. En cambio, el segundo método dependía de forma sustancial del estado de la sesión de Spark. En la primera ejecución consecutiva, los tiempos de ejecución rondaban los 15 segundos, muy distintos a los tiempos de las ejecuciones posteriores, que rondaban entre 5 y 6 segundos.\n",
    "\n",
    "Debido a esto, se tomó la decisión de elegir el primer método para q1_time, únicamente por su estabilidad. Cabe considerar que, en el caso de tener un ambiente de ejecución más estable, el segundo método podría ofrecer mejores resultados a largo plazo.\n",
    "\n",
    "En cuanto al uso de memoria, este fue un análisis más directo. Con el método 1, siempre se observó un uso de hasta 1300 MiB, muy por encima del método 2, que rondaba los 300 MiB de forma constante. Por ende, se seleccionó el método 2 para q1_memory"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metodo 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Se ejecuto multiples veces y siempre se consigui un tiempo de ejecucion de alrededor de 11s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_time import  q1_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f q1_time q1_time(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f q1_time q1_time(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -f q1_time q1_time(file_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Mem pregunta 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from q1_memory import  q1_memory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f q1_memory q1_memory(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%lprun -f q1_memory q1_memory(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -f q1_memory q1_memory(file_path=file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para este problema se tomó un enfoque similar al de la pregunta anterior, pero a diferencia de esta, para el tiempo se utilizó PySpark y para la memoria, funciones convencionales.\n",
    "\n",
    "Dado que solo es necesario contar ocurrencias a nivel de registro, se puede iterar fila por fila.\n",
    "\n",
    "Lamentablemente, este enfoque no obtuvo los resultados esperados, y la metodología sin PySpark utilizó prácticamente la misma cantidad de memoria que la que usaba PySpark, e incluso más en algunas pruebas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "your 131072x1 screen size is bogus. expect trouble\n",
      "24/10/14 22:54:59 WARN Utils: Your hostname, pescara-pc resolves to a loopback address: 127.0.1.1; using 10.255.255.254 instead (on interface lo)\n",
      "24/10/14 22:54:59 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "24/10/14 22:55:00 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 18.4042 s\n",
      "File: /home/sandbox/files/latam-challenge/src/q2_time.py\n",
      "Function: q2_time at line 44\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    44                                           def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "    45         1 3905414685.0    4e+09     21.2      spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
      "    46                                           \n",
      "    47         1 5956659988.0    6e+09     32.4      data = spark.read.json(file_path)\n",
      "    48         1  335665521.0    3e+08      1.8      dataframe = get_most_used_emojis(spark, data)\n",
      "    49                                           \n",
      "    50         1       1793.0   1793.0      0.0      del data\n",
      "    51                                           \n",
      "    52         2      27091.0  13545.5      0.0      output = [\n",
      "    53         1 7216616653.0    7e+09     39.2          tuple(row) for row in dataframe.select([col(\"emoji\"), col(\"count\")]).collect()\n",
      "    54                                               ]\n",
      "    55                                           \n",
      "    56         1  989797668.0    1e+09      5.4      spark.stop()\n",
      "    57                                           \n",
      "    58         1        291.0    291.0      0.0      return output"
     ]
    }
   ],
   "source": [
    "from q2_time import  q2_time\n",
    "\n",
    "%lprun -f q2_time q2_time(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/sandbox/files/latam-challenge/src/q2_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    44    174.9 MiB    174.9 MiB           1   def q2_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "    45    174.9 MiB      0.0 MiB           1       spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
      "    46                                         \n",
      "    47    174.9 MiB      0.0 MiB           1       data = spark.read.json(file_path)\n",
      "    48    174.9 MiB      0.0 MiB           1       dataframe = get_most_used_emojis(spark, data)\n",
      "    49                                         \n",
      "    50    174.9 MiB      0.0 MiB           1       del data\n",
      "    51                                         \n",
      "    52    174.9 MiB      0.0 MiB          24       output = [\n",
      "    53    174.9 MiB      0.0 MiB          11           tuple(row) for row in dataframe.select([col(\"emoji\"), col(\"count\")]).collect()\n",
      "    54                                             ]\n",
      "    55                                         \n",
      "    56    174.9 MiB      0.0 MiB           1       spark.stop()\n",
      "    57                                         \n",
      "    58    174.9 MiB      0.0 MiB           1       return output"
     ]
    }
   ],
   "source": [
    "%mprun -f q2_time q2_time(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "*** KeyboardInterrupt exception caught in code being profiled."
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 9.83701 s\n",
      "File: /home/sandbox/files/latam-challenge/src/q2_memory.py\n",
      "Function: q2_memory at line 7\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     7                                           def q2_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     8         1        912.0    912.0      0.0      result = dict()\n",
      "     9         2     451684.0 225842.0      0.0      with open(file_path, \"r\") as f:\n",
      "    10                                                   # En el archivo hay un json por linea, hay que itearr y extrar cada uno\n",
      "    11      3080   55925861.0  18157.7      0.6          for line in f:\n",
      "    12      3080 8193672422.0    3e+06     83.3              data = pd.json_normalize(json.loads(line))\n",
      "    13      6158  311252272.0  50544.4      3.2              for c in data.content.to_list():\n",
      "    14      4139 1274725765.0 307979.2     13.0                  for e in emoji.emoji_list(c):\n",
      "    15      1060     983372.0    927.7      0.0                      result[e[\"emoji\"]] = result.get(e[\"emoji\"], 0) + 1\n",
      "    16                                           \n",
      "    17                                           \n",
      "    18                                               top_emojis = pd.json_normalize(result).T.reset_index().sort_values(0,ascending=False).head(10)\n",
      "    19                                                   \n",
      "    20                                               out = []\n",
      "    21                                               for index, row in top_emojis.iterrows():\n",
      "    22                                                   out.append((row.loc[\"index\"], row.loc[0]))\n",
      "    23                                           \n",
      "    24                                               return out"
     ]
    }
   ],
   "source": [
    "from q2_memory import  q2_memory\n",
    "\n",
    "%lprun -f q2_memory q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%mprun -f q2_memory q2_memory(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pregunta 3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Problemática similar al ejercicio anterior, salvo por la diferencia de que el dato venía dentro de una lista de JSONs y no en un texto plano (exceptuando el hecho de que se tenían que extraer emojis).\n",
    "\n",
    "Por esta razón, se tomó un enfoque similar al de la pregunta anterior, con resultados similares."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 2.58777 s\n",
      "File: /home/sandbox/files/latam-challenge/src/q3_time.py\n",
      "Function: q3_time at line 25\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "    25                                           def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "    26         1   96438348.0    1e+08      3.7      spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
      "    27                                           \n",
      "    28         1  669796235.0    7e+08     25.9      data = spark.read.json(file_path)\n",
      "    29         1   52012522.0    5e+07      2.0      dataframe = get_most_mentions(spark, data)\n",
      "    30                                           \n",
      "    31         1        471.0    471.0      0.0      del data\n",
      "    32                                           \n",
      "    33         2      10800.0   5400.0      0.0      output = [\n",
      "    34         1 1319767472.0    1e+09     51.0          tuple(row) for row in dataframe.select([col(\"username\"), col(\"count\")]).collect()\n",
      "    35                                               ]\n",
      "    36                                           \n",
      "    37         1  449748132.0    4e+08     17.4      spark.stop()\n",
      "    38                                           \n",
      "    39         1        240.0    240.0      0.0      return output"
     ]
    }
   ],
   "source": [
    "from q3_time import  q3_time\n",
    "\n",
    "%lprun -f q3_time q3_time(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/sandbox/files/latam-challenge/src/q3_time.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "    25    177.3 MiB    177.3 MiB           1   def q3_time(file_path: str) -> List[Tuple[str, int]]:\n",
      "    26    177.3 MiB      0.0 MiB           1       spark = SparkSession.builder.appName(APP_NAME).getOrCreate()\n",
      "    27                                         \n",
      "    28    177.3 MiB      0.0 MiB           1       data = spark.read.json(file_path)\n",
      "    29    177.3 MiB      0.0 MiB           1       dataframe = get_most_mentions(spark, data)\n",
      "    30                                         \n",
      "    31    177.3 MiB      0.0 MiB           1       del data\n",
      "    32                                         \n",
      "    33    177.3 MiB      0.0 MiB          24       output = [\n",
      "    34    177.3 MiB      0.0 MiB          11           tuple(row) for row in dataframe.select([col(\"username\"), col(\"count\")]).collect()\n",
      "    35                                             ]\n",
      "    36                                         \n",
      "    37    177.3 MiB      0.0 MiB           1       spark.stop()\n",
      "    38                                         \n",
      "    39    177.3 MiB      0.0 MiB           1       return output"
     ]
    }
   ],
   "source": [
    "%mprun -f q3_time q3_time(file_path=file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Timer unit: 1e-09 s\n",
      "\n",
      "Total time: 310.855 s\n",
      "File: /home/sandbox/files/latam-challenge/src/q3_memory.py\n",
      "Function: q3_memory at line 6\n",
      "\n",
      "Line #      Hits         Time  Per Hit   % Time  Line Contents\n",
      "==============================================================\n",
      "     6                                           def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     7         1       1473.0   1473.0      0.0      result = dict()\n",
      "     8         2      48370.0  24185.0      0.0      with open(file_path, \"r\") as f:\n",
      "     9                                                   # En el archivo hay un json por linea, hay que itearr y extrar cada uno\n",
      "    10    117408 1857681054.0  15822.4      0.6          for line in f:\n",
      "    11    117407        3e+11    3e+06     97.2              data = pd.json_normalize(json.loads(line))\n",
      "    12    117407 3157675293.0  26895.1      1.0              if \"quotedTweet.mentionedUsers\" in data.columns: # Hay registros que no tienen la columna\n",
      "    13     41436 3320505758.0  80135.8      1.1                  if data[\"quotedTweet.mentionedUsers\"][0]: # Y otros que vienen con \"None\"\n",
      "    14     23579  136426022.0   5785.9      0.0                      for u in data[\"quotedTweet.mentionedUsers\"][0]:\n",
      "    15     16075   20249099.0   1259.7      0.0                          result[u[\"username\"]] = result.get(u[\"username\"], 0) + 1\n",
      "    16                                               \n",
      "    17         1  110276925.0    1e+08      0.0      top_mentions = pd.json_normalize(result).T.reset_index().sort_values(0,ascending=False).head(10)\n",
      "    18                                                   \n",
      "    19         1        421.0    421.0      0.0      out = []\n",
      "    20        11    1249477.0 113588.8      0.0      for index, row in top_mentions.iterrows():\n",
      "    21        10     977957.0  97795.7      0.0          out.append((row.loc[\"index\"], row.loc[0]))\n",
      "    22                                           \n",
      "    23         1        141.0    141.0      0.0      return out"
     ]
    }
   ],
   "source": [
    "from q3_memory import  q3_memory\n",
    "\n",
    "%lprun -f q3_memory q3_memory(file_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/sandbox/files/latam-challenge/src/q3_memory.py\n",
      "\n",
      "Line #    Mem usage    Increment  Occurrences   Line Contents\n",
      "=============================================================\n",
      "     6    179.5 MiB    179.5 MiB           1   def q3_memory(file_path: str) -> List[Tuple[str, int]]:\n",
      "     7    179.5 MiB      0.0 MiB           1       result = dict()\n",
      "     8    185.5 MiB      0.0 MiB           2       with open(file_path, \"r\") as f:\n",
      "     9                                                 # En el archivo hay un json por linea, hay que itearr y extrar cada uno\n",
      "    10    185.5 MiB      0.1 MiB      117408           for line in f:\n",
      "    11    185.5 MiB      5.8 MiB      117407               data = pd.json_normalize(json.loads(line))\n",
      "    12    185.5 MiB      0.1 MiB      117407               if \"quotedTweet.mentionedUsers\" in data.columns: # Hay registros que no tienen la columna\n",
      "    13    185.5 MiB      0.1 MiB       41436                   if data[\"quotedTweet.mentionedUsers\"][0]: # Y otros que vienen con \"None\"\n",
      "    14    185.5 MiB      0.0 MiB       23579                       for u in data[\"quotedTweet.mentionedUsers\"][0]:\n",
      "    15    185.5 MiB      0.0 MiB       16075                           result[u[\"username\"]] = result.get(u[\"username\"], 0) + 1\n",
      "    16                                             \n",
      "    17    185.5 MiB      0.0 MiB           1       top_mentions = pd.json_normalize(result).T.reset_index().sort_values(0,ascending=False).head(10)\n",
      "    18                                                 \n",
      "    19    185.5 MiB      0.0 MiB           1       out = []\n",
      "    20    185.5 MiB      0.0 MiB          11       for index, row in top_mentions.iterrows():\n",
      "    21    185.5 MiB      0.0 MiB          10           out.append((row.loc[\"index\"], row.loc[0]))\n",
      "    22                                         \n",
      "    23    185.5 MiB      0.0 MiB           1       return out"
     ]
    }
   ],
   "source": [
    "%mprun -f q3_memory q3_memory(file_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
